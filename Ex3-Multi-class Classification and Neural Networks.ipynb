{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize as opt\n",
    "from scipy import io as spio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set(style=\"darkgrid\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "mat=spio.loadmat('machine-learning-ex3/ex3/ex3data1.mat')\n",
    "X,y=mat['X'],mat['y']\n",
    "y[y==10]=0 # convert label '10' back to 0 as 0 is labeled '10' in dataset \n",
    "\n",
    "mat=spio.loadmat('machine-learning-ex3/ex3/ex3weights.mat')\n",
    "theta1,theta2=mat['Theta1'],mat['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the data (to be completed...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# construct regularized cost function and gradient\n",
    "def cost_ftn(theta,X,y,alpha):\n",
    "    sample_size=X.shape[0]\n",
    "    lc=np.dot(X,theta)\n",
    "    cost=-sum(y*np.log(sigmoid(lc))+(1-y)*np.log(1-sigmoid(lc)))/sample_size\\\n",
    "    +alpha/(2*sample_size)*np.dot(theta[1:].T,theta[1:])\n",
    "    return cost.ravel()\n",
    "\n",
    "def gradient(theta,X,y,alpha):\n",
    "    sample_size=X.shape[0]\n",
    "    lc=np.dot(X,theta)\n",
    "    delta=sigmoid(lc)-y\n",
    "    theta=np.insert(theta[1:],0,0).reshape(len(theta),1)\n",
    "    gradient=np.dot(X.T,delta)/sample_size+alpha/sample_size*theta\n",
    "    return gradient.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at test theta: 2.535\n",
      "Gradient at test theta:\n",
      "[ 0.147 -0.549  0.725  1.398]\n"
     ]
    }
   ],
   "source": [
    "# test cost function and gradient\n",
    "theta_test=np.array([-2,-1,1,2]).reshape(4,1)\n",
    "X_test=np.array(range(1,16)).reshape(3,5).T/10\n",
    "X_test=np.insert(X_test,0,1,axis=1)\n",
    "y_test=np.array([1,0,1,0,1]).reshape(5,1)\n",
    "alpha_test=3\n",
    "cost_test=cost_ftn(theta_test,X_test,y_test,alpha_test)\n",
    "gradient_test=gradient(theta_test,X_test,y_test,alpha_test)\n",
    "\n",
    "print(\"Cost at test theta: {0:.3f}\".format(np.asscalar(cost_test)))\n",
    "print(\"Gradient at test theta:\")\n",
    "print(np.round(gradient_test,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted prob vector for sample [0]:\n",
      "[ 0.996  0.     0.001  0.     0.     0.002  0.     0.     0.     0.002]\n",
      "Predicted digit for sample [0]: 0\n",
      "\n",
      "Accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "# sklearn LogisticRegression API implements multi-class as one-vs-all\n",
    "lr=LogisticRegression(solver='newton-cg') # slight difference in results due to 'fmincg', not 'fminnc' used in MatLab\n",
    "lr.fit(X,y)\n",
    "predicted_prb=lr.predict_proba(X)\n",
    "predicted=lr.predict(X)\n",
    "\n",
    "print('Predicted prob vector for sample [0]:')\n",
    "print(np.round(predicted_prb[0],3))\n",
    "print('Predicted digit for sample [0]: {}'.format(predicted[0]))\n",
    "print('\\nAccuracy: {0:.1f}%'.format(accuracy_score(y,predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted prob vector for sample [0]:\n",
      "[ 0.996  0.     0.001  0.     0.     0.002  0.     0.     0.     0.002]\n",
      "Predicted digit for sample [0]: 0\n",
      "\n",
      "Accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "# one-vs-all classification approach deconstructed; results same as above\n",
    "predicted_prb=np.ndarray(shape=(X.shape[0],10))\n",
    "for i in range(10):\n",
    "    y_bin=(y==i).astype(int)\n",
    "    lr.fit(X,y_bin)\n",
    "    predicted_prb[:,i]=lr.predict_proba(X)[:,1]\n",
    "predicted=np.argmax(predicted_prb,axis=1)\n",
    "\n",
    "print('Predicted prob vector for sample [0]:')\n",
    "print(np.round(predicted_prb[0],3))\n",
    "print('Predicted digit for sample [0]: {}'.format(predicted[0]))\n",
    "print('\\nAccuracy: {0:.1f}%'.format(accuracy_score(y,predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted prob vector for sample [0]:\n",
      "[ 0.     0.002  0.003  0.     0.009  0.004  0.006  0.     0.006  0.996]\n",
      "Predicted digit for sample [0]: 0\n",
      "\n",
      "Accuracy: 97.5%\n"
     ]
    }
   ],
   "source": [
    "# prediction using neural networks with previously trained weights \n",
    "X_bias=np.insert(X,0,1,axis=1)\n",
    "units2=sigmoid(np.dot(X_bias,theta1.T))\n",
    "units2=np.insert(units2,0,1,axis=1)\n",
    "predicted_prb=sigmoid(np.dot(units2,theta2.T))\n",
    "predicted=np.argmax(predicted_prb,axis=1)+1\n",
    "predicted[predicted==10]=0\n",
    "\n",
    "print('Predicted prob vector for sample [0]:')\n",
    "print(np.round(predicted_prb[0],3))\n",
    "print('Predicted digit for sample [0]: {}'.format(predicted[0]))\n",
    "print('\\nAccuracy: {0:.1f}%'.format(accuracy_score(y,predicted)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
